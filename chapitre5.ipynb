{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapitre5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvuH9dnQkr3m"
      },
      "source": [
        "exercice1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCSJKoAZnL8-"
      },
      "source": [
        "# Define params_dt\n",
        "params_dt = {\n",
        "    'max_depth':[2,3,4],\n",
        "    'min_samples_leaf': [0.12,0.14,0.16,0.18]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQxuXX8xnNAQ"
      },
      "source": [
        "exercice2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n11wFXDbobxU"
      },
      "source": [
        "# Import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Instantiate grid_dt\n",
        "grid_dt = GridSearchCV(estimator=dt,\n",
        "                       param_grid=params_dt,\n",
        "                       scoring='roc_auc',\n",
        "                       cv=5,\n",
        "                       n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joL5PdLhpYZV"
      },
      "source": [
        "exercice 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "webMjsJBpaG0"
      },
      "source": [
        "# Import roc_auc_score from sklearn.metrics\n",
        "from sklearn.metrics import roc_auc_score \n",
        "\n",
        "# Extract the best estimator\n",
        "best_model = grid_dt.best_estimator_\n",
        "\n",
        "# Predict the test set probabilities of the positive class\n",
        "\n",
        "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Compute test_roc_auc\n",
        "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Print test_roc_auc\n",
        "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwvd-MRys-fu"
      },
      "source": [
        "exercice4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxrSYf1funLP"
      },
      "source": [
        "# Define the dictionary 'params_rf'\n",
        "params_rf = {\n",
        "    'n_estimators':[100,350,500],\n",
        "    'max_features':['log2','auto','sqrt'],\n",
        "    'min_samples_leaf':[2, 10, 30],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtE2nBXXxBQN"
      },
      "source": [
        "exercice5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO10jBa1xEdH"
      },
      "source": [
        "# Import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Instantiate grid_rf\n",
        "grid_rf = GridSearchCV(estimator=rf,\n",
        "                       param_grid=params_rf,\n",
        "                       scoring='neg_mean_squared_error',\n",
        "                       cv=3,\n",
        "                       verbose=1,\n",
        "                       n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70uz1l-dxk6e"
      },
      "source": [
        "exercice 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2OcqpgyxnDu"
      },
      "source": [
        "# Import mean_squared_error from sklearn.metrics as MSE \n",
        "from sklearn.metrics import mean_squared_error as MSE \n",
        "\n",
        "# Extract the best estimator\n",
        "best_model = grid_rf.best_estimator_\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Compute rmse_test\n",
        "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
        "\n",
        "# Print rmse_test\n",
        "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}